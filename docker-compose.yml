version: '3.9' 
services:

  spark-master:
    build: 
      context: .
      dockerfile: ./Docker/Spark/Dockerfile
    image: spark:3.3
    container_name: spark-master
    hostname: spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    ports:
      - 8080:8080
      - 7077:7077
    stdin_open: true
    tty: true

  spark-worker:
    build: 
      context: .
      dockerfile: ./Docker/Spark-worker/Dockerfile
    image: spark-worker:3.3
    depends_on:
      - spark-master
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_MODE=worker
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    stdin_open: true
    tty: true
    deploy:
      mode: replicated
      replicas: 4


  # spark-notebook:
  #   image: jupyter/pyspark-notebook
  #   container_name: pyspark-notebook
  #   depends_on:
  #     - spark-master
  #   command: jupyter notebook --ip=0.0.0.0 --port=8888 --no-browser --allow-root
  #   ports:
  #     - 9999:8888

  mongo:
    image: mongo
    container_name: mongo
    restart: always
    ports:
      - 27017:27017
  
  etl-runner:
    build: 
      context: .
      dockerfile: ./Docker/Python-runner/Dockerfile
    image: python-runner
    container_name: etl-runner
    volumes: 
      - ./:/etc/project
    working_dir: /etc/project/Scripts
    command: python etl.py --fileName=sample.json
    depends_on:
      - mongo


  pyspark-runner:
    build: 
      context: .
      dockerfile: ./Docker/pySpark-runner/Dockerfile
    image: pyspark-runner
    container_name: pyspark-runner
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - MONGO_HOST=mongodb://mongo:27017
    volumes: 
      - ./:/etc/project
    working_dir: /etc/project/Scripts
    command: python spark_trending.py --fileName=sample.json
    depends_on:
      - mongo
      - etl-runner
            #wait till etl-runner finished


  api-services:
    build: 
      context: .
      dockerfile: ./Docker/Python-runner/Dockerfile
    image: python-runner
    container_name: api-services
    volumes: 
      - ./:/etc/project
    working_dir: /etc/project/Scripts
    command: python api.py 
    depends_on:
      - mongo
      - etl-runner
      - pyspark-runner
    ports:
      - 8383:8383

# networks:
#   connector: